# docker-compose.yml
services:
  db:
    image: postgres:15-alpine # Use a specific version
    container_name: dicom_processor_db
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-dicom_processor_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_DB: ${POSTGRES_DB:-dicom_processor_db}
    ports:
      - "${POSTGRES_PORT:-5432}:5432" # Expose DB port to host (use .env or default)
    healthcheck:
        test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-dicom_processor_user} -d ${POSTGRES_DB:-dicom_processor_db}"]
        interval: 5s
        timeout: 5s
        retries: 5
    restart: unless-stopped

  rabbitmq:
    image: rabbitmq:3.12-management-alpine # Use specific version with management UI
    container_name: dicom_processor_rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-guest}
      # RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST:-/} # Usually not needed unless changing vhost
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"   # AMQP port
      - "15672:15672" # Management UI port (access via http://localhost:15672)
    healthcheck:
        test: ["CMD", "rabbitmqctl", "status"]
        interval: 10s
        timeout: 5s
        retries: 5
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq/
    restart: unless-stopped

  redis:
    image: redis:7-alpine # Use a specific alpine version
    container_name: dicom_processor_redis
    command: redis-server --save 60 1 --loglevel warning # Optional: Persistence & log level
    volumes:
      - redis_data:/data
#    ports:
      # Optional: Expose Redis port to host ONLY if needed for external debugging
      # - "6379:6379"
    healthcheck:
        test: ["CMD", "redis-cli", "ping"]
        interval: 5s
        timeout: 3s
        retries: 5
    restart: unless-stopped

  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dicom_processor_api
    # Load environment variables from .env file for the container
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy # Wait for DB to be ready
      rabbitmq:
        condition: service_healthy # Wait for RabbitMQ to be ready
      redis:
        condition: service_healthy
    ports:
      - "8001:80" # Map host port 8000 to container port 80 (where uvicorn runs)
    volumes:
      - ./app:/app/app # Mount local 'app' directory into container for live reload
      - ./alembic.ini:/app/alembic.ini     # <-- ADD: Mount alembic.ini to /app/
      - ./alembic:/app/alembic             # <-- ADD: Mount alembic dir to /app/
    # Override command for development to enable reload
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "80", "--reload", "--proxy-headers", "--forwarded-allow-ips='*'"]
    restart: unless-stopped

  orthanc: # <--- ADD THIS NEW SERVICE
    image: orthancteam/orthanc:24.3.4
    container_name: orthanc
    restart: unless-stopped
    ports:
      - "8042:8042" # Expose Orthanc's HTTP port (for Web UI & DICOMweb)
      - "4242:4242" # Expose Orthanc's DICOM C-STORE port (for uploading data)
    volumes:
      - ./orthanc/config:/etc/orthanc # Mount local config directory
      - orthanc_db:/var/lib/orthanc/db # Persistent storage for Orthanc data/db
    environment:
      # Set credentials Orthanc will use (adjust as needed)
      ORTHANC_USERNAME: orthancuser
      ORTHANC_PASSWORD: orthancpassword
      VERBOSE_ENABLED: "true" # Enable verbose logging within Orthanc container
      # Set default Orthanc Storage location (matches volume mount)
      # ORTHANC__STORAGE_DIRECTORY: "/var/lib/orthanc/db"
      # Enable PostgreSQL backend (Optional - Requires DB setup inside Orthanc)
      # POSTGRES_HOST: "db" # Needs to talk to your 'db' service
      # POSTGRES_PORT: "5432"
      # POSTGRES_USER: "${ORTHANC_DB_USER:-orthanc_db_user}" # Use a separate DB user?
      # POSTGRES_PASSWORD: "${ORTHANC_DB_PASSWORD:-changeme_orthanc_db}"
      # POSTGRES_DATABASE: "${ORTHANC_DB_NAME:-orthanc_db}"
      # ORTHANC__POSTGRESQL__ENABLE_STORAGE: "true" # Enable Postgres storage area
      # ORTHANC__POSTGRESQL__ENABLE_INDEX: "true" # Enable Postgres index
      # Leave PostgreSQL commented out for now to use default SQLite for simplicity
    healthcheck:
        test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8042/app/explorer.html"]
        interval: 10s
        timeout: 5s
        retries: 5

  beat:
    build:
      context: .
      dockerfile: Dockerfile.worker # Can use the same image as worker
    container_name: dicom_processor_beat
    env_file:
      - .env
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      db: # Might need DB access if schedule stored in DB later
         condition: service_healthy
    # Command to start beat
    command: ["celery", "-A", "app.worker.celery_app.app", "beat", "--loglevel=info"] # Example using DB scheduler
    # OR use default scheduler: command: ["celery", "-A", "app.worker.celery_app.app", "beat", "--loglevel=info"]
    restart: unless-stopped

  # Example worker service - scale this as needed
  worker:
    build:
      context: .
      dockerfile: Dockerfile.worker
    container_name: dicom_processor_worker
    env_file:
      - .env
    depends_on:
      rabbitmq:
        condition: service_healthy
      db: # Worker might need DB access too
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./app:/app/app # Mount code for consistency, though reload isn't typical for workers
      # Mount DICOM data directories if using filesystem storage/input within docker
      - dicom_incoming:/dicom_data/incoming
      - dicom_processed:/dicom_data/processed
    # The CMD from Dockerfile.worker is used unless overridden here
    # command: ["celery", "-A", "app.worker.celery_app.app", "worker", "--loglevel=info", "-c", "2"] # Example override
    restart: unless-stopped

  listener:
    build:
      context: .
      dockerfile: Dockerfile.listener
    container_name: dicom_processor_listener # Or maybe listener_storescp_1? Your choice.
    env_file:
      - .env
    environment:
      - AXIOM_INSTANCE_ID=storescp_1 # Unique ID for this instance
    depends_on:
      rabbitmq: # Needs rabbitmq to dispatch tasks
        condition: service_healthy
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    ports:
      # Map HOST_PORT to the CONTAINER_PORT defined in the DB config for storescp_1
      # Example: Expose container port 11112 (matching DB config) as host port 11112
      - "11112:11112/tcp"
      # Example: Expose container port 11112 as host port 10104
      # - "10104:11112/tcp"
    volumes:
      - ./app:/app/app # Mount code for consistency
      - dicom_incoming:/dicom_data/incoming # Needs write access to the incoming volume
    restart: unless-stopped

  listener_2: # Define the second listener service
    build:
      context: .
      dockerfile: Dockerfile.listener # Can use the same image
    container_name: dicom_processor_listener_2 # Unique container name
    env_file:
      - .env # Use the same common environment variables
    environment:
      - AXIOM_INSTANCE_ID=storescp_2 # Unique instance ID matching DB record 2
    depends_on: # Same dependencies
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    ports:
      # Map host port 11113 to container port 11113 (matching DB config for storescp_2)
      - "11113:11113/tcp"
    volumes: # Same volumes
      - ./app:/app/app
      - dicom_incoming:/dicom_data/incoming
    restart: unless-stopped

  listener_3: # Define the second listener service
    build:
      context: .
      dockerfile: Dockerfile.listener # Can use the same image
    container_name: dicom_processor_listener_3 # Unique container name
    env_file:
      - .env # Use the same common environment variables
    environment:
      - AXIOM_INSTANCE_ID=storescp_3 # Unique instance ID matching DB record 2
    depends_on: # Same dependencies
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      db:
        condition: service_healthy
    ports:
      # Map host port 11113 to container port 11113 (matching DB config for storescp_2)
      - "11114:11114/tcp"
    volumes: # Same volumes
      - ./app:/app/app
      - dicom_incoming:/dicom_data/incoming
    restart: unless-stopped

volumes:
  postgres_data:
  rabbitmq_data:
  dicom_incoming:
  dicom_processed:
  dicom_errors:
  redis_data:
  orthanc_db:
